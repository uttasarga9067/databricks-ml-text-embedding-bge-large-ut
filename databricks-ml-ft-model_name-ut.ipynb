{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1281c4eb-12e1-4000-85c1-23922bf50ccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6f8782ac1d40b8a9bce9d5add34418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "014ad095-09c9-4498-b512-2387b638573d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:27: UserWarning: This dataset can not be stored in DBFS because either `cache_dir` or the environment variable `HF_DATASETS_CACHE` is set to a non-DBFS path. If this cluster restarts, all saved dataset information will be lost.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7394e836264248c5b846520d41ed393e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python_shell/dbruntime/huggingface_patches/datasets.py:13: UserWarning: During large dataset downloads, there could be multiple progress bar widgets that can cause performance issues for your notebook or browser. To avoid these issues, use `datasets.utils.logging.disable_progress_bar()` to turn off the progress bars.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae00373b0794d5c98a59f6cd360f1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d078911342184ff88c185325cc76557e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/247M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08e1b26cc834717845623a82da0172a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b927b177df8f41f0bea7fdf0d18ae348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'query': 'What is the length and width of this scooter in inches?',\n",
       " 'pos': ['below are all the products specs- We are authorized dealers and offer fast shipping- Also 1 year warranty FREE Phillips Health care he EW-36 mobility scooter is a 3 wheel high-power mobility scooter using a transaxle brushless electric motor. At full power the EW-36 can reach speed up to 18 mph which makes it easily the fastest mobility scooter on the market! Up to 45 mile range per single charge! Also included a reverse switch, armrest and large storage basket. The EW-36 comes equipped with a digital anti-theft alarm and two rear shock absorbers on the frame. The EW-36 is a great scooter for both fun and transportation. COLOR: Red, Silver, Blue, Orange, Camo POWER: Electric WATTS: 500 Watt MOTOR TYPE: Transaxle differential brushless motor AMPS: 20 AH VOLTS: 48 Volt DIMENSIONS: 61\"*29\"*41\" BATTERIES: 48 volt lead acid maintenance free battery TIRE SIZE: 16\"/2.5\" CHARGER: Smart charger included SPEED: Up to 18mph DISTANCE: Up to 45 miles per charge (distance varies by riders weight , terrain, road surface etc.) THROTTLE TYPE: Variable speed control- Twist Throttle KEY START: Yes BRAKING SYSTEM: Front and rear braking system DRIVE SYSTEM: Brushless motor HEAD LIGHT: Yes CARTON SIZE: Shipped on a pallet SHIPPING WEIGHT: 280 lbs NET WEIGHT: 200 lbs ELECTRIC LIGHT: Yes BATTERY INDICATOR: Yes STORAGE BASKET: Yes SHOCK ABSORBER: Two rear shock absorber on the frame ALARM: Anti-theft alarm']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "output_model_path = \"/dbfs/fine_tuned_bge_v1_5_model\"\n",
    "\n",
    "dataset = load_dataset(\"embedding-data/Amazon-QA\", split = 'train[:500]')\n",
    "\n",
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75cefe4b-3010-4522-98ee-d0f0c92e2223",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 05:38:01.451378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2023-12-02 05:38:01.451484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2023-12-02 05:38:01.457287: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-12-02 05:38:02.680530: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "\n",
    "def create_dataset_for_multiple_loss(train_dataset):\n",
    "    train_examples = []\n",
    "    for elem in train_dataset:\n",
    "        query = f\"Represent this sentence for searching relevant passages: {elem['query']}\"\n",
    "        texts = elem[\"pos\"]\n",
    "\n",
    "    for text in texts:\n",
    "        train_examples.append(InputExample(texts=[query,text]))\n",
    "    return train_examples\n",
    "\n",
    "train_examples = create_dataset_for_multiple_loss(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e24d208-94ea-4059-8986-7c8fec19718b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e3ca545ccc43ba9270b04ee497eab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading .gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6258cf6218b145fe8bea56d1bd54f079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading 1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc9ac6e1fc9491aabd0252e049e3517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading README.md:   0%|          | 0.00/90.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f736a36b384f6e92c32cb25ee5815f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87e105eb34841089028da529879e130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ce_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf06b83843649a884493b4d7fd6ac70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85355ce7c3cc4b018e23deaa313fbd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)nce_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d4207e98f049108b7ae16e85c0619e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad05913314ae47a5bfa9af55eef4e8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bd487ef4994c4d9f95c5f30972b980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63477f45b3a34d308fbdcf27a854e833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfb1609c94c4d0192a325d7f7261be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da03a4bbf24c4bd4b2d2b912ef1a6593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dd7bd063ad4fc2970f0d6a55b42a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb51f3ce08ab4c1f8925169cfb61c5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064632ebbd3b45ac9b239ec50ad6f4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('BAAI/bge-large-en-v1.5')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=3)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d563b5b-ff52-4e57-8e2b-118da2d4532f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.save(output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "765c2409-2c29-4790-ba46-4bc816f47e46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    " \n",
    "class SentenceTransformerEmbeddingModel(mlflow.pyfunc.PythonModel):\n",
    "  def load_context(self, context):\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    self.model = SentenceTransformer(context.artifacts[\"sentence-transformer-model\"], device=device)\n",
    "    \n",
    "  def predict(self, context, model_input): \n",
    "    texts = model_input.iloc[:, 0].to_list()  # get the first column\n",
    "    sentence_embeddings = self.model.encode(texts)\n",
    "    return pd.Series(sentence_embeddings.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3228cd-eb24-4689-a9ac-0642d46a646d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from mlflow.utils.environment import _mlflow_conda_env\n",
    "import accelerate\n",
    "import sentence_transformers\n",
    "import cloudpickle\n",
    "EMBEDDING_CONDA_ENV = _mlflow_conda_env(\n",
    "    additional_pip_deps=[\n",
    "        f\"accelerate=={accelerate.__version__}\",\n",
    "        f\"cloudpickle=={cloudpickle.__version__}\",\n",
    "        f\"sentence-transformers=={sentence_transformers.__version__}\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37f305f-fae2-4f36-940f-eb71c9be32da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/02 05:39:04 WARNING mlflow.models.signature: Failed to infer the model signature from the input example. Reason: AttributeError(\"'list' object has no attribute 'iloc'\"). To see the full traceback, set the logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)`. To disable automatic signature inference, set `signature` to `False` in your `log_model` or `save_model` call.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c97330d05804965b9fb5127d92e1dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/02 05:39:04 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3ef10aa3dd44b08b76032e5efa19a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/02 05:39:09 INFO mlflow.store.artifact.cloud_artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005fac047a31433f9bfec2deb09b7125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /local_disk0/repl_tmp_data/ReplId-6c9d2-23938-df28d-4/tmpbo4yqxsj/model/artifacts/fine_tuned_bge_v1_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "  my_model = SentenceTransformerEmbeddingModel()\n",
    "  model_info = mlflow.pyfunc.log_model(artifact_path=\"model\", python_model=my_model, input_example=[\"London is known for its finacial district\"], artifacts={\"sentence-transformer-model\": output_model_path}, conda_env=EMBEDDING_CONDA_ENV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "370996d5-3a7e-45c6-bf3a-e5653b319ebb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b152291993eb4550a099d76c291f5066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/02 05:44:52 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf71b29709aa48eda42dc7d498936d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading /tmp/tmpij9i47uv/model/artifacts/fine_tuned_bge_v1_5_model/pytorch_model.bin:   0%|          | 0.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2525483273307466>, line 8\u001B[0m\n",
       "\u001B[1;32m      5\u001B[0m run_id \u001B[38;5;241m=\u001B[39m run\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n",
       "\u001B[1;32m      6\u001B[0m logged_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 8\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mload_model(logged_model)\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Predict on a Pandas DataFrame.\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m test_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLondon has 9,787,426 inhabitants at the 2011 census\u001B[39m\u001B[38;5;124m'\u001B[39m,\n",
       "\u001B[1;32m     12\u001B[0m               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLondon is known for its finacial district\u001B[39m\u001B[38;5;124m'\u001B[39m], columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:679\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001B[0m\n",
       "\u001B[1;32m    677\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(conf[MAIN])\u001B[38;5;241m.\u001B[39m_load_pyfunc(data_path, model_config)\n",
       "\u001B[1;32m    678\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 679\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mMAIN\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pyfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    681\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m conf[MAIN] \u001B[38;5;241m==\u001B[39m _DATABRICKS_FS_LOADER_MODULE:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/pyfunc/model.py:396\u001B[0m, in \u001B[0;36m_load_pyfunc\u001B[0;34m(model_path, model_config)\u001B[0m\n",
       "\u001B[1;32m    391\u001B[0m     artifacts[saved_artifact_name] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n",
       "\u001B[1;32m    392\u001B[0m         model_path, saved_artifact_info[CONFIG_KEY_ARTIFACT_RELATIVE_PATH]\n",
       "\u001B[1;32m    393\u001B[0m     )\n",
       "\u001B[1;32m    395\u001B[0m context \u001B[38;5;241m=\u001B[39m PythonModelContext(artifacts\u001B[38;5;241m=\u001B[39martifacts, model_config\u001B[38;5;241m=\u001B[39mmodel_config)\n",
       "\u001B[0;32m--> 396\u001B[0m \u001B[43mpython_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    397\u001B[0m signature \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mload(model_path)\u001B[38;5;241m.\u001B[39msignature\n",
       "\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _PythonModelPyfuncWrapper(\n",
       "\u001B[1;32m    399\u001B[0m     python_model\u001B[38;5;241m=\u001B[39mpython_model, context\u001B[38;5;241m=\u001B[39mcontext, signature\u001B[38;5;241m=\u001B[39msignature\n",
       "\u001B[1;32m    400\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m<command-2525483273307461>, line 9\u001B[0m, in \u001B[0;36mSentenceTransformerEmbeddingModel.load_context\u001B[0;34m(self, context)\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_context\u001B[39m(\u001B[38;5;28mself\u001B[39m, context):\n",
       "\u001B[1;32m      8\u001B[0m   device \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
       "\u001B[0;32m----> 9\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43martifacts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentence-transformer-model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:107\u001B[0m, in \u001B[0;36mSentenceTransformer.__init__\u001B[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001B[0m\n",
       "\u001B[1;32m    104\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    105\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse pytorch device: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(device))\n",
       "\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target_device \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "\u001B[0;31mRuntimeError\u001B[0m: Device index must not be negative"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)\nFile \u001B[0;32m<command-2525483273307466>, line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m run_id \u001B[38;5;241m=\u001B[39m run\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m      6\u001B[0m logged_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mruns:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrun_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/model\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m loaded_model \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mload_model(logged_model)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Predict on a Pandas DataFrame.\u001B[39;00m\n\u001B[1;32m     11\u001B[0m test_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLondon has 9,787,426 inhabitants at the 2011 census\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     12\u001B[0m               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLondon is known for its finacial district\u001B[39m\u001B[38;5;124m'\u001B[39m], columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:679\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001B[0m\n\u001B[1;32m    677\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(conf[MAIN])\u001B[38;5;241m.\u001B[39m_load_pyfunc(data_path, model_config)\n\u001B[1;32m    678\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 679\u001B[0m         model_impl \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mMAIN\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pyfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    681\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m conf[MAIN] \u001B[38;5;241m==\u001B[39m _DATABRICKS_FS_LOADER_MODULE:\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/mlflow/pyfunc/model.py:396\u001B[0m, in \u001B[0;36m_load_pyfunc\u001B[0;34m(model_path, model_config)\u001B[0m\n\u001B[1;32m    391\u001B[0m     artifacts[saved_artifact_name] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    392\u001B[0m         model_path, saved_artifact_info[CONFIG_KEY_ARTIFACT_RELATIVE_PATH]\n\u001B[1;32m    393\u001B[0m     )\n\u001B[1;32m    395\u001B[0m context \u001B[38;5;241m=\u001B[39m PythonModelContext(artifacts\u001B[38;5;241m=\u001B[39martifacts, model_config\u001B[38;5;241m=\u001B[39mmodel_config)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mpython_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    397\u001B[0m signature \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mModel\u001B[38;5;241m.\u001B[39mload(model_path)\u001B[38;5;241m.\u001B[39msignature\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _PythonModelPyfuncWrapper(\n\u001B[1;32m    399\u001B[0m     python_model\u001B[38;5;241m=\u001B[39mpython_model, context\u001B[38;5;241m=\u001B[39mcontext, signature\u001B[38;5;241m=\u001B[39msignature\n\u001B[1;32m    400\u001B[0m )\n\nFile \u001B[0;32m<command-2525483273307461>, line 9\u001B[0m, in \u001B[0;36mSentenceTransformerEmbeddingModel.load_context\u001B[0;34m(self, context)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_context\u001B[39m(\u001B[38;5;28mself\u001B[39m, context):\n\u001B[1;32m      8\u001B[0m   device \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 9\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43martifacts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msentence-transformer-model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:107\u001B[0m, in \u001B[0;36mSentenceTransformer.__init__\u001B[0;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001B[0m\n\u001B[1;32m    104\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    105\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse pytorch device: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(device))\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_target_device \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\n\u001B[0;31mRuntimeError\u001B[0m: Device index must not be negative",
       "errorSummary": "<span class='ansi-red-fg'>RuntimeError</span>: Device index must not be negative",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "run_id = run.info.run_id\n",
    "logged_model = f\"runs:/{run_id}/model\"\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "test_df = pd.DataFrame(['London has 9,787,426 inhabitants at the 2011 census',\n",
    "              'London is known for its finacial district'], columns=[\"text\"])\n",
    "\n",
    "loaded_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3849268c-092d-4fad-a814-600bc80757f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2525483273307464>, line 6\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Add the instruction to each entry in the \"text\" column\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRepresent this sentence for searching relevant passages: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
       "\u001B[0;32m----> 6\u001B[0m model\u001B[38;5;241m.\u001B[39mpredict(test_df)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n",
       "\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n",
       "\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n",
       "\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'SentenceTransformer' object has no attribute 'predict'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2525483273307464>, line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Add the instruction to each entry in the \"text\" column\u001B[39;00m\n\u001B[1;32m      5\u001B[0m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRepresent this sentence for searching relevant passages: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m test_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m model\u001B[38;5;241m.\u001B[39mpredict(test_df)\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n\n\u001B[0;31mAttributeError\u001B[0m: 'SentenceTransformer' object has no attribute 'predict'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'SentenceTransformer' object has no attribute 'predict'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(['London has 9,787,426 inhabitants at the 2011 census',\n",
    "                        'London is known for its finacial district'], columns=[\"text\"])\n",
    "\n",
    "# Add the instruction to each entry in the \"text\" column\n",
    "test_df['text'] = 'Represent this sentence for searching relevant passages: ' + test_df['text']\n",
    "loaded_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c531db-5897-457f-826e-8a216eb2dcfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03b94491-c866-4689-b15a-91ffff8ef446",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2525483273307456>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_to_hub\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m01GangaPutraBheeshma/01databricksmlftbgelargeenUT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSentence Transformers\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAdd a new SentenceTransformer Model from Databricks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n",
       "\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreplace_model_card\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_datasets\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43membedding-data/Amazon-QA\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:464\u001B[0m, in \u001B[0;36mSentenceTransformer.save_to_hub\u001B[0;34m(self, repo_name, organization, private, commit_message, local_model_path, exist_ok, replace_model_card, train_datasets)\u001B[0m\n",
       "\u001B[1;32m    462\u001B[0m         repo_name \u001B[38;5;241m=\u001B[39m splits[\u001B[38;5;241m1\u001B[39m]\n",
       "\u001B[1;32m    463\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 464\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou passed and invalid repository name: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(repo_name))\n",
       "\u001B[1;32m    466\u001B[0m endpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://huggingface.co\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    467\u001B[0m repo_url \u001B[38;5;241m=\u001B[39m HfApi(endpoint\u001B[38;5;241m=\u001B[39mendpoint)\u001B[38;5;241m.\u001B[39mcreate_repo(\n",
       "\u001B[1;32m    468\u001B[0m         token,\n",
       "\u001B[1;32m    469\u001B[0m         repo_name,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    473\u001B[0m         exist_ok\u001B[38;5;241m=\u001B[39mexist_ok,\n",
       "\u001B[1;32m    474\u001B[0m     )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: You passed and invalid repository name: 01GangaPutraBheeshma/01databricksmlftbgelargeenUT."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\nFile \u001B[0;32m<command-2525483273307456>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_to_hub\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m01GangaPutraBheeshma/01databricksmlftbgelargeenUT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSentence Transformers\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcommit_message\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAdd a new SentenceTransformer Model from Databricks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreplace_model_card\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_datasets\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43membedding-data/Amazon-QA\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:464\u001B[0m, in \u001B[0;36mSentenceTransformer.save_to_hub\u001B[0;34m(self, repo_name, organization, private, commit_message, local_model_path, exist_ok, replace_model_card, train_datasets)\u001B[0m\n\u001B[1;32m    462\u001B[0m         repo_name \u001B[38;5;241m=\u001B[39m splits[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 464\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou passed and invalid repository name: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(repo_name))\n\u001B[1;32m    466\u001B[0m endpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://huggingface.co\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    467\u001B[0m repo_url \u001B[38;5;241m=\u001B[39m HfApi(endpoint\u001B[38;5;241m=\u001B[39mendpoint)\u001B[38;5;241m.\u001B[39mcreate_repo(\n\u001B[1;32m    468\u001B[0m         token,\n\u001B[1;32m    469\u001B[0m         repo_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    473\u001B[0m         exist_ok\u001B[38;5;241m=\u001B[39mexist_ok,\n\u001B[1;32m    474\u001B[0m     )\n\n\u001B[0;31mValueError\u001B[0m: You passed and invalid repository name: 01GangaPutraBheeshma/01databricksmlftbgelargeenUT.",
       "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: You passed and invalid repository name: 01GangaPutraBheeshma/01databricksmlftbgelargeenUT.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save_to_hub(\n",
    "    repo_name =\"01GangaPutraBheeshma/01databricksmlftbgelargeenUT\",\n",
    "    organization=\"Sentence Transformers\",\n",
    "    commit_message = \"Add a new SentenceTransformer Model from Databricks\",\n",
    "    exist_ok = False, \n",
    "    replace_model_card= False, \n",
    "    train_datasets = \"embedding-data/Amazon-QA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b23f2d68-6fef-4492-8eb3-6fe1c2265056",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_to_hub(repo_name: str, organization: Optional[str] = None, private: Optional[bool] = None, commit_message: str = 'Add new SentenceTransformer model.', local_model_path: Optional[str] = None, exist_ok: bool = False, replace_model_card: bool = False, train_datasets: Optional[List[str]] = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "608e4bec-14c3-480e-a916-d7ce075676eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "databricks-ml-ft-model_name-ut",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
